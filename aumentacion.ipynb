{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio: *Aumentación de Datos con Modelos Generativos en el Dominio del Monotributo (AFIP)*\n",
        "\n",
        "En el año 2020, nuestro grupo de investigación participó en el Proyecto de Transferencia de Tecnología: “BillMobile: un prototipo de chatbot basado en IA para mejorar la calidad de experiencia del cliente”. Como resultado, se obtuvo una colección de preguntas relacionadas con el Régimen de Monotributo de la Administración Federal de Ingresos Públicos (AFIP). Durante el proyecto, se aplicaron diversos enfoques de aprendizaje automático, incluyendo modelos basados en Transformers.\n",
        "\n",
        "A pesar de haberse desarrollado un estudio integral, uno de los principales desafíos fue la **cantidad limitada de ejemplos por clase en la colección de preguntas**, lo que restringió el desempeño de los modelos entrenados.\n",
        "\n",
        "Actividad propuesta:\n",
        "Diseñar una estrategia de aumentación de datos utilizando modelos generativos actuales para ampliar la colección original de preguntas. El objetivo es generar nuevas muestras  que enriquezcan el conjunto de datos en cada una de las clases definidas durante el proceso de etiquetado.\n",
        "\n",
        "*  Formular prompts optimizados para generar nuevas preguntas sintéticas, cuidando que estén alineadas semánticamente con cada categoría.\n",
        "*   Utilizar los resultados obtenidos en la Notebook anterior para ajustar y refinar dichos prompts, priorizando la calidad y relevancia de las muestras generadas."
      ],
      "metadata": {
        "id": "lg9yMU1vYTk1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQL-IZGPX-cU"
      },
      "source": [
        "# Parte 1: Aumentación de Datos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd aumentacion"
      ],
      "metadata": {
        "id": "ksCCWd1WYe3-",
        "outputId": "9a9c7919-109f-47bf-e3ab-5c0e4ae905f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'aumentacion'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IqyorGsZX-cW",
        "outputId": "8bb08df3-80d4-4043-8942-900c981e4226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'aumentacion'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-1895002722.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0maumentacion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m labels = [\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'cantidad'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'definicion'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'aumentacion'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from aumentacion import *\n",
        "\n",
        "labels = [\n",
        "    'cantidad',\n",
        "    'definicion',\n",
        "    'entidad',\n",
        "    'manera',\n",
        "    'procedimiento',\n",
        "    'razon',\n",
        "    'referencia',\n",
        "    'si_no',\n",
        "    'temporal',\n",
        "    'ubicacion'\n",
        "]\n",
        "\n",
        "dataset_path = './dataset.csv'\n",
        "template_path = './template.txt'\n",
        "augmented_set_path = './augmented_set.csv'\n",
        "classifier_path = './classifier'\n",
        "\n",
        "llm_data = {\n",
        "    'url': \"http://localhost:1234/v1/chat/completions\",\n",
        "    'llm_name': 'mistralai/mistral-7b-instruct-v0.3'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADY6OzeAX-cX"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(dataset_path, labels)\n",
        "template = get_file_content(template_path)\n",
        "\n",
        "llm_answers = ask_llm_to_augment(labels, dataset, template, llm_data)\n",
        "augmented_set = parse_llm_answers(llm_answers)\n",
        "save_as_csv(augmented_set, augmented_set_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8immIvG7X-cX"
      },
      "source": [
        "# Parte 2: Evaluación del Conjunto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXmAiRVtX-cY"
      },
      "outputs": [],
      "source": [
        "augmented_set = load_augmented_set(augmented_set_path)\n",
        "\n",
        "predictions = ask_classifier_to_predict(classifier_path, labels, augmented_set['question'])\n",
        "eval_augmented_set(augmented_set['label'], predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MG1YTjtX-cY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}